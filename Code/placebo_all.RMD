---
title: "placebo_final"
author: "Fiori Anglou"
date: "2024-06-25"
output: pdf_document
editor_options: 
  chunk_output_type: console
---
##############
To replicate the results of Fig. 2, panel B, look at section "State" and subsection "Fig. 2: Placebo distribution". 
Required sections to run before sunning subsection "Fig. 2: Placebo distribution": basic data, functions, pre-processing 
#################
```{r, include=FALSE}
library(ggplot2)
library(dplyr)
library(tidyverse)
library(ggpubr)
library(stringr)
library(fixest)
library(knitr)
library(zoo)
library(tidyr)
library(tictoc)
library(purrr)
library(extrafont)
#state_data_path <- "C:/Users/fa24575/Dropbox/Organic Waste Bans/03. State_Data"
#post_syp_path <- "C:/Users/fa24575/Dropbox/Organic Waste Bans/06. Post SYP"
#figure_path <- "C:/Users/fa24575/Dropbox/Apps/Overleaf/Organic Waste Bans/Figures"
#municipal_path <- "C:/Users/fa24575/Dropbox/Organic Waste Bans/03.1. Municipal Data"

mypathname <-"C:/Users/fa24575/Dropbox/Organic Waste Bans"
municipal_path <- paste0(mypathname, "/03.1. Municipal Data")
state_data_path <- paste0(mypathname,"/03. State_Data")
base_path <- paste0(mypathname,"/06. Post SYP/00. Code/")
figure_path <- "C:/Users/fa24575/Dropbox/Apps/Overleaf/Organic Waste Bans/Figures"

```


# Basic Data


```{r, include=FALSE}
loadfonts(device = "win")

ut_colors <- c(
  rgb(132, 59,14, max=255), # dark orange
  rgb(255, 127, 21, max=255), # bright orange
  rgb(191,87,0, max=255), # ut orange
  rgb(51,73,72, max=255), # dark grey
  rgb(156, 173, 183, max=255), #light grey
  rgb(191,87,0,alpha=50, max=255))# ut orange

# Population
population <- read.csv(paste0(state_data_path,"/00. Controls/Population/population.csv"))
population <- cbind(population[1:2], stack(population[3:31]))
colnames(population)<- c("state_id", "county_name", "pop", "year")
population$year <- substring(population$year, 2) %>% as.integer
population$pop <- as.numeric(population$pop)
population$county_name[population$county_name=="doña ana"] <- "dona ana"
population <- population[population$state_id!="AK" & population$state_id!="co" & population$state_id!="ia",] # contiguous states, DC is considered a contiguous state

population_2020 <- read.csv(paste0(state_data_path,"/00. Controls/Population/population_2020.csv"))
population_2020 <- population_2020[population_2020$state_id !="DC",]
population_2020$county_name[population_2020$county_name=="doña ana"] <- "dona ana"
population <- rbind(population, population_2020)
rm(population_2020)


# Waste Data
#power2 <- read.csv("power2_2.csv")
power2 <- read.csv(file=paste0(base_path,"power2_impexp.csv"))
all_treated <- c("VT", "MA", "CA", "CT", "RI")# Never changes
bans <- c(2014, 2014, 2016, 2014, 2016)
#bans <- c(2014, 2014, 2016, 2014, 2016)
bans_passage <- c(2012, 2013, 2014, 2011, 2014) #passage dates
year_start <- 2006
year_end <- 2018
```

## Functions
```{r, include=FALSE}

do_many_times_v3 <- function (i, x, test_ind_end1, test_ind_end2,y_train, y_test, y_att, n_don,sample_size)
{
  #Approach 2- Only Intercept
  samples <- sample(n_don, sample_size)
  x <- rowMeans(x[, samples]) # This is for sample size > 1
  #x=x[, samples] # This is for sample size equal to 1
  n <- length(y_train)+ length(y_test) + length(y_att)

  intercept <- mean(y_train-x[1:test_ind_end1])

  ss_res <- sum((y_train-x[1:test_ind_end1] - intercept)^2) #calculating the in-sample R-squared
  ss_tot <- sum((y_train-mean(y_train))^2)
  r <- 1- ss_res/ss_tot
  MA  <- (intercept + x[(test_ind_end1+1):test_ind_end2] - y_test )/(intercept + x[(test_ind_end1+1):test_ind_end2]) 
  MA <- MA %>% abs %>%  mean

  att <- (y_att-x[(test_ind_end2+1):n]-intercept) %>% sum
  cf <- (x[(test_ind_end2+1):n]+intercept) %>% sum
  c(r, MA, att, cf, c(samples))
  intercept2 <-  mean(c(y_train, y_test)-x[1:test_ind_end2])
  att <- (y_att-x[(test_ind_end2+1):n]-intercept2) %>% sum
  cf <- (x[(test_ind_end2+1):n]+intercept2) %>% sum
  c(r, MA, att, cf, c(samples))

  
  # 
  # samples <- sample(n_don, sample_size)
  # x <- rowMeans(x[, samples])
  # n <- length(y_train)+ length(y_test) + length(y_att)
  # 
  # x_train <- x[1:test_ind_end1]
  # x_test <-  x[(test_ind_end1+1):test_ind_end2]
  # x_att <- x[(test_ind_end2+1):n]
  # 
  # coef <- sum((x_train - mean(x_train)) * (y_train - mean(y_train))) / sum((x_train - mean(x_train))^2)
  # intercept <- mean(y_train)-coef * mean(x_train)
  # 
  # MA <- mean(abs((intercept + x_test * coef - y_test) / y_test))
  # #att <- sum(intercept + x_att * coef - y_att)
  # cf <-(intercept + x_att * coef ) %>% sum
  # att <- (y_att - intercept - x_att * coef) %>% sum
  # #ss_res <- sum((y_train - intercept - x_train * coef)^2)
  # #ss_tot <- sum((y_train - mean(y_train))^2)
  # r <- 1 - sum((y_train - intercept - x_train * coef)^2) /  sum((y_train - mean(y_train))^2)
  # c(r, MA, att, cf, c(samples))

}

in_sample_R2_v2 <- function (k, dt, donors,iterations_scale, option, ban_year, offset, samp)
{
  ###
  # This function creates the SC using the identification method we describe in the paper 
  # It returns for each sample_size the 100 best SC (best means that these SCs have the lowest MAPE)
  ###
  
  treated_location <- donors[k] #the placebo state
  year_end <- ban_year-offset # the start of the validation period
  state_treated <- ifelse( #the placebo state, this serves the case where the treated location is a county and thus we want to exclude all the counties in the same state
    str_length(treated_location)>2, 
    substr(treated_location, str_length(treated_location)-1, str_length(treated_location)), 
    treated_location)
  
  don_new <- donors[donors!=treated_location] #the donor pool
  don_new <- #the donor pool, this serves the case where the treated location is a county and thus we want to exclude all the counties in the same state
    don_new %>% 
    as_tibble %>% 
    mutate(
      state = ifelse( 
        str_length(value)>2, 
        substr(value, str_length(value)-1, str_length(value)), 
        value)
    ) %>% 
    filter(
      state != state_treated
    ) %>% as.data.frame()
  
  don_new <- don_new[,"value"]
  
  n_don <- length(don_new)                              #number of potential donors
  test_ind_end1 <- year_end - year_start+1              #end of training period 
  test_ind_end2 <- ban_year-year_end-1 +test_ind_end1   #end of validation period 
  
  y <- dt[dt$county_id==treated_location, c("tons_pc")] #actual disposal per capita of the treated state  
  y_train <- y[1:test_ind_end1]                         #disposal series during training period
  y_test <-  y[(test_ind_end1+1):test_ind_end2]         #disposal series during validation period
  y_att <- y[(test_ind_end2+1):length(y)]               #disposal series during the post-ban period
  
  x <- dt[!dt$county_id %in% treated_counties_id,]      #actual disposal per capita of the potential donors
  x <- as.matrix(unstack(x, tons_pc ~ county_id)) 

  
  res <- tibble( #initializing results table
    r_sq = 0, 
    mape = 0, 
    att=0, 
    cf=0, 
    sample_size=0, 
    county_id ="", 
    iterations = 0, 
    ban_year = 0, 
    donor_number="", 
    chosen_donor=0
  )
  
  for ( f in 1:length(samp)) #for each potential value of |S| (in our case |S| can be between 3 and 10)
  {
    sample_size <- samp[f]
    iterations <- iterations_scale #min(iterations_scale* sample_size, 15000)

    all <- lapply(seq(1:iterations),do_many_times_v3,x, test_ind_end1, test_ind_end2,y_train, y_test, y_att,n_don, sample_size)
    all <- all %>% sapply(c) %>% t
    
    colnames(all) <- c(
      "r_sq",
      "mape", 
      "att",
      "cf",
      paste0(rep("donor", sample_size), paste0("_", c(1:sample_size)))
    )
    
    all <- 
      all %>% 
      as_tibble %>%
      #filter(r_sq > 0) %>% #from the SC that have in sample R_sq >0 
      arrange(mape) %>% 
      slice(1:100) %>% # keep the 100 that have the lowest MAPE
      mutate(
        sample_size = samp[f], 
        county_id = treated_location, 
        iterations = iterations, 
        ban_year = ban_year,
        att = att/cf
      ) %>%  
      pivot_longer(
        cols = c(paste0(rep("donor", sample_size), paste0("_", c(1:sample_size)))), 
        names_to = "donor_number", 
        values_to = "chosen_donor"
      )
    
    res <- rbind(res, all)
  }
  res %>% 
    as_tibble 
}

in_sample_R2_same_state <- function (k, dt, donors,iterations_scale, option, ban_year, offset, samp, seed)
{
  #### 
  # this is the same function as in_sample_R2_v2 but for SF 
  # (The difference is that it is allowed to choose donors from the same state, which is need for SF) 
  ####
  
  set.seed(seed)
  treated_location <- donors[k]
  year_end <- ban_year-offset
  
  don_new <- donors[donors!=treated_location]

  n_don <- length(don_new)
  test_ind_end1 <- year_end - year_start+1
  test_ind_end2 <- ban_year-year_end-1 +test_ind_end1
  
  y <- dt[dt$county_id==treated_location, "tons_pc"]
  y_train <- y[1:test_ind_end1]
  y_test <- y[(test_ind_end1+1): test_ind_end2]
  y_att <- y[(test_ind_end2+1): length(y)]
  
  x <- dt[dt$county_id!=treated_location, c("tons_pc", "county_id")]
  x <- as.matrix(unstack(x, tons_pc ~ county_id)) 

  res <- tibble(
    r_sq = 0, 
    mape = 0, 
    att=0, 
    cf=0, 
    sample_size=0, 
    county_id ="", 
    iterations = 0, 
    ban_year = 0, 
    donor_number="", 
    chosen_donor=0
  )
  
  for ( f in 1:length(samp))
  {
    sample_size <- samp[f]
    iterations <- min(iterations_scale* sample_size, 10000)

    all <- lapply(seq(1:iterations),do_many_times_v3,x, test_ind_end1, test_ind_end2,y_train, y_test, y_att,n_don, sample_size)
    all <- all %>% sapply(c) %>% t
    
    colnames(all) <- c(
      "r_sq",
      "mape", 
      "att",
      "cf",
      paste0(rep("donor", sample_size), paste0("_", c(1:sample_size)))
    )
    
    all <- 
      all %>% 
      as_tibble %>%
      filter(r_sq > 0) %>% 
      arrange(mape) %>% 
      slice(1:100) %>% 
      mutate(
        sample_size = samp[f], 
        county_id = treated_location, 
        iterations = iterations, 
        ban_year = ban_year,
        att = att/cf
      ) %>%  
      pivot_longer(
        cols = c(paste0(rep("donor", sample_size), paste0("_", c(1:sample_size)))), 
        names_to = "donor_number", 
        values_to = "chosen_donor"
      )
    
    res <- rbind(res, all)
  }
  res %>% 
    as_tibble 
}

power_state_plac <- function(treated_state, dt_state_initial, seed)
{
  ###
  # This function creates the re-centered dataset for each ban 
  # and returns the best 100 SC for each sample size 
  ###
  
  set.seed(seed)
  ####
  # we recenter the time series of the treated states based on when the ban went into effect, i.e., for VT it went into effect in July so we recenter the time series so it starts in July
  ####
  if(treated_state == "MA")
  {
    dt_state <- dt_state_initial %>%group_by(state_id) %>% 
      mutate(
        tons_pc = tons_pc*0.25 + .75*ifelse(is.na(lag(tons_pc, n=1, default = NA)), tons_pc, lag(tons_pc, n=1, default = NA)) 
      )
  }else if(treated_state == "VT")
  {
    dt_state <- dt_state_initial %>%group_by(state_id) %>% 
      mutate(
        tons_pc = tons_pc*.5 + .5*ifelse(is.na(lag(tons_pc, n=1, default = NA)), tons_pc, lag(tons_pc, n=1, default = NA)) 
      )
  }else if(treated_state == "CA")
  {
    dt_state <- dt_state_initial %>%group_by(state_id) %>% 
      mutate(
        tons_pc = tons_pc*.75 + .25*ifelse(is.na(lag(tons_pc, n=1, default = NA)), tons_pc, lag(tons_pc, n=1, default = NA)) 
      )
  }else{dt_state <- dt_state_initial}
  
  dt_state <- dt_state %>%  as.data.frame()
  treated_counties_id <- unique(dt_state$county_id[dt_state$state_id%in% all_treated])
  dt_state <- dt_state[!(dt_state$state_id %in% all_treated),] %>% as.data.frame
  donors_state <- unique(dt_state$county_id[!(dt_state$state_id%in% all_treated)])
  
  ban_year <- bans[which(all_treated == treated_state)]#the ban year of the treated state
  
  ###
  # apply function in_sample_R2_v2 to all the non-treated states
  # Function in_sample_R2_v2 essentially creates the 100000 SC and returns 
  # the 100 best SCs. 
  ###
  
  plac <- lapply(seq(1:length(donors_state)),in_sample_R2_v2,dt_state, donors=donors_state, iterations_scale=100000, option="V2", ban_year=ban_year, offset=3, samp =samp)

  return(plac)
  
}

power_state_fun2 <- function(plac, treated_state)
{
  #### 
  # This function creates the placebo intervals
  # In this function, plac (the input) is the result of the placebo runs (i.e., the ATT, the mape etc)
  
  # For the state-level specification we use the SC with the lowest MAPE and create the placebo intervals (the output of the function)
  
  ####
  
  spec4 <- 
    plac %>% 
    bind_rows() %>% 
    filter(sample_size!=0) %>% 
    mutate(county_id = as.character(county_id)) %>% 
    group_by(sample_size, ban_year, county_id ) %>% 
    filter(mape==min(mape)) %>% #choose the SC with the minimum MAPE
    summarise(att = mean(att)) %>% # if there are mulptiple SC wth the same min MAPE take the mean of their ATTs
    group_by(sample_size, ban_year) %>%     
    summarise(
      att_min = quantile(att, 0.05), #because our sample is not super large the quantile 0.025 averages across observations and gives us an att that does not exist. We could choose either the largest or the 2nd largest att as our quantile. Given that the round(0.025*(22)+1) gives us 2 we choose the 2nd observation (that is because 22 is the sample size)
      att_max = quantile(att, 0.95), 
      att_median = mean(att)
    ) 

  
  specs <-
    rbind(
      spec4 %>%  mutate (specification = "State") 
    ) %>% mutate(
      year = ban_year, 
      treated_state = treated_state
    )
  
  return(specs)
  
}

power_state_fun2_alternative <- function(plac, treated_state)
{
  
  ######
  # This is the same  function as power_state_fun2
  # The only difference is that instead of calculating the placebo interval using the
  # second-min and the second-max ATT, we use the actual 2.5 and 97.5 quantiles (which
  #take an avg between the min and the second-min and the max and the second-max)
  ######
  
  spec4 <- 
    plac %>% 
    bind_rows() %>% 
    filter(sample_size!=0) %>% 
    mutate(county_id = as.character(county_id)) %>% 
    group_by(sample_size, ban_year, county_id ) %>% 
    filter(mape==min(mape)) %>% 
    summarise(att = mean(att)) %>% 
    group_by(sample_size, ban_year) %>%     
    summarise(
      att_min = quantile(att, 0.025), 
      att_max = quantile(att, 0.975), 
      att_median = mean(att)
    ) 
  

  specs <-
    rbind(
      spec4 %>%  mutate (specification = "State")
    ) %>% mutate(
      year = ban_year, 
      treated_state = treated_state
    )
  
  return(specs)
  
}

power_county <- function(plac, treated_state)
{
  ###
  # This function is similar to the: power_state_fun2
  # The only difference is that here, we use county-level datasets
  ###
  
  dt <- dt_initial
  spec1 <-
    plac%>%
    bind_rows() %>%
    filter(sample_size!=0) %>%
    group_by(sample_size, county_id, ban_year) %>%
    #filter(mape==min(mape)) %>% # when we do not include this filter we get higher power, Results remain qualitatively the same (the optimal |S| changes to 5 for seattle (they provide the same power) and 4 for boulder. )
    summarise(att = mean(att)) %>% 
    group_by(sample_size, ban_year) %>%
    summarise(
      att_min = quantile(att, 0.025),
      att_max = quantile(att, 0.975),
      att_median = mean(att)
    )

  specs <-
    rbind(
      spec1 %>%  mutate (specification = "County") 
    ) %>% mutate(
      year = ban_year,
      treated_state = treated_state
    )

  return(specs)
}

power_county_for_hist <- function(treated_state, dt_initial, seed)
{
  set.seed(seed)
  if(treated_state=="MA")
  {
    dt <- dt_initial %>%group_by(county_id) %>% 
      mutate(
        tons_pc = tons_pc*0.25 + .75*ifelse(is.na(lag(tons_pc, n=1, default = NA)), tons_pc, lag(tons_pc, n=1, default = NA)) 
      )
  }else if(treated_state == "VT")
  {
    dt <- dt_initial %>%group_by(county_id) %>% 
      mutate(
        tons_pc = tons_pc*.5 + .5*ifelse(is.na(lag(tons_pc, n=1, default = NA)), tons_pc, lag(tons_pc, n=1, default = NA)) 
      )
  }else if(treated_state == "CA")
  {
    dt <- dt_initial %>%group_by(county_id) %>% 
      mutate(
        tons_pc = tons_pc*.75 + .25*ifelse(is.na(lag(tons_pc, n=1, default = NA)), tons_pc, lag(tons_pc, n=1, default = NA)) 
      )
  }else {dt <- dt_initial}
  
  dt <- dt %>%  as.data.frame()
  treated_counties_id <- unique(dt$county_id[dt$state_id%in% all_treated])
  dt <- dt[!(dt$state_id %in% all_treated),] %>% as.data.frame
  donors <- unique(dt$county_id[!(dt$state_id%in% all_treated)])
  
  ban_year <- bans[which(all_treated == treated_state)]
  
  plac <- lapply(seq(1:length(donors)),in_sample_R2_v2,dt, donors=donors, iterations_scale=10000, option="V2", ban_year=ban_year, offset=4, samp =samp)
  
  return(plac)
}

pool_function <-function(i, data, donors, r_threshold,mape_threshold,n, seed)
{
  set.seed(seed)
  donors <- tibble(
    county_id =donors, 
    num_id = 1:length(donors)
  )
  
  pooled <- 
    data %>%
    left_join(
      donors, 
      by = c("county_id")
    ) %>% 
    group_by(county_id) %>% 
    mutate(
      pools = sample(nrow(donors),n) %>% list()
    )%>% 
    ungroup #choose at random five states and consider them treated
  
  
  pooled %>%
    mutate(
      num_id = num_id %>% as.integer
    ) %>% 
    filter(
      num_id %in% (
        pooled%>% 
          filter(num_id==i) %>% 
          slice(1) %>% 
          pluck("pools") %>% 
          unlist
      )
    ) %>% 
    group_by(sample_size, ban_year, county_id) %>%
    filter(mape==min(mape)) %>% # of these five states choose the SC that has the min mape
    summarise(
      att=mean(att), # the mean serves two purposes: 1) if there's two SC with the same MAPE take the avg of the two 2) because of the way that the dataset is structured for each chosen donor in the SC there's one line (where the ATT, R_sq and MAPE are the same ofc) to collapse these lines we use the mean 
      r_sq=mean(r_sq), 
      mape=mean(mape), 
      cf= mean(cf)) %>% 
    group_by(sample_size, ban_year) %>% 
    summarise(
      att = sum(att*cf)/sum(cf), #and finally, to find the ATT of the aggregate case, take the mean of the five chosen states. 
      mape = mean(mape), 
      r_sq = mean(r_sq), 
      i
    ) %>% 
    ungroup
}
```

# Pre-Processing

## County
```{r, include=FALSE}
pre_processing_dt <- function(power2)
{
  year_start <- 2006
  year_cutoff <- 2018
  year_end <- 2011
  
  dt <- power2
  
  
  dt_ca <- 
    dt %>% 
    filter(
      year >= year_start, 
      year <= year_cutoff, 
      type %in% c("disposal", "msw_disposed"),
      state_id=="CA"
    ) %>% 
    group_by(county_name) %>% 
    mutate(
      tons_high = quantile(tons, 0.975), 
      tons_low = quantile(tons, 0.025), 
      tons = ifelse(tons> tons_high, tons_high, tons), 
      tons = ifelse(tons< tons_low, tons_low, tons)
    ) %>% 
    select(-tons_high) %>% select(-tons_low) %>% ungroup
    
  
  
  dt <- 
    dt %>% 
    as_tibble() %>% 
    filter(state_id!="CA") %>% 
    rbind(
      dt_ca
    ) %>% 
    filter(
      year >= year_start, 
      year <= year_cutoff, 
      type %in% c("disposal", "msw_disposed")
    ) %>% 
    group_by (year, state_id, county_name) %>% 
    summarise(tons = sum(tons)) %>% 
    left_join (
      population %>% group_by(state_id, year) %>% summarise(state_pop = sum(pop)), 
      by = c("state_id", "year")
    ) %>%
    left_join (
      population,
      by = c("state_id", "county_name", "year")
    ) %>% 
    mutate(
      tons_pc = ifelse(is.na(county_name),tons/state_pop, tons/pop), 
      county_id = ifelse(is.na(county_name), state_id, paste0(county_name, state_id) )
    ) %>% 
    filter(
     tons_pc > 0.2
    )

  #Exclude missing values and small values
  exc<- 
    as.data.frame(
      dt %>% 
        group_by(county_id) %>% 
        #filter(state_id != "CT", state_id != "RI") %>% 
        summarize(
          m = mean(tons_pc), 
          min_year = min(year), 
          min_tons = min(tons_pc), 
          max_tons = max(tons_pc)) %>%
        filter(
          m < 0.3 | min_year > year_start )#| max_tons > 2.5)
    ) %>% as_tibble()
  
  dt <- dt[!(dt$county_id %in% exc$county_id),]
  dt <- dt[dt$year >=year_start  & dt$year <=year_cutoff,]
  exc<- 
    as.data.frame(
      dt %>% 
        group_by(county_id) %>% 
        summarize(n=  n()) %>% 
        filter(
          n < (year_cutoff- year_start+1)
        )
    )
  dt <- dt[!(dt$county_id %in% exc$county_id),]
  # Percentage change in disposal tons
  f <- 
    as.data.frame(
      dt %>% 
        filter(#state_id != "RI", state_id!="CA", 
               !is.na(county_name)) %>% 
        group_by(county_id) %>% 
        mutate(
          percentage = (tons-dplyr::lag(tons, n = 1, default = NA))/dplyr::lag(tons, n = 1, default = NA),
          percentage_1 = (tons-dplyr::lead(tons, n = 1, default = NA))/dplyr::lead(tons, n = 1, default = NA)
        )
    )
  
  f <- f[!is.na(f$percentage),]
  threshold <- 0.42
  exclude2 <- unique(f$county_id[#f$percentage > threshold | f$percentage < -threshold 
  f$percentage_1 > threshold | f$percentage_1 < -threshold])
  #dt %>% filter(county_id %in% exclude2, year == 2014) %>% ungroup %>% summarise(sum(tons))/
  #dt %>% filter(year == 2014) %>% ungroup %>% summarise(sum(tons))
  
  
  dt <- dt[!dt$county_id %in% exclude2,]
  
  rm(f, exc, exclude2)
  
  dt_initial <- dt
  return(dt_initial)
}
```

## State

```{r}
pre_processing_dt_state <- function (power2)
{
  
  year_start <- 2006
  year_cutoff <- 2018
  dt_state <- 
    power2 %>% 
    mutate(county_id=paste0(county_name, state_id)) %>% 
    #filter(!county_id%in%c(rural)) %>% 
    group_by (year, state_id, type) %>% 
    summarise(tons = sum(tons))%>% 
    filter(
      year >= year_start, 
      year <= year_cutoff,
      type %in% c("disposal", "msw_disposed")
    ) %>%
    group_by(state_id) %>% 
    left_join (
      population %>% group_by(state_id, year) %>% summarise(state_pop = sum(pop)), 
      by = c("state_id", "year")
    ) %>%
    group_by(state_id, year) %>% 
    mutate(
      tons_pc = (tons/state_pop), 
      county_id = state_id
    ) %>% 
    group_by(state_id) %>% 
    mutate(n=n()) %>% 
    filter(n == year_cutoff - year_start+1) %>% 
    select(-n) %>% 
    ungroup() 
  
  # dt_state <- 
  #   dt_state %>% 
  #   group_by(state_id) %>% 
  #   mutate(
  #     lag = ifelse(is.na(lag(tons_pc, n=1, default = NA)), tons_pc, lag(tons_pc, n=1, default = NA)), 
  #     tons_pc = 100*(tons_pc - lag)/lag
  #   ) 
  
  dt_state_initial <- dt_state
  return(dt_state_initial)
  
}
```

# Power
## County

### SC Results

The following chunk produces the SCs required to derive the "power" for the city-level analysis (Boulder and Seattle)

```{r}

samp = c(3:10)
dt_initial <- pre_processing_dt (power2)
donors <- unique(dt_initial$county_id[!(dt_initial$state_id%in% all_treated)])
treated_counties_id <- unique(dt_initial$county_id[dt_initial$state_id%in% all_treated])

plac_for_histogram4 <- power_county_for_hist("CA", dt_initial, 1) #for county-level SCs we want to keep only the SCs with R-sq>0. To do so in_sample_R2_v2 needs to change. Go to line 207 and uncomment command: "#filter(r_sq > 0) %>% #from the SC that have in sample R_sq >0" 



all_treated <- c("VT", "MA", "CA", "CT", "RI", "M1", "M2")
bans <- c(2014, 2014, 2016, 2014, 2016, 2015, 2016)
plac_for_histogram6 <- power_county_for_hist("M1", dt_initial, 1)
all_treated <- c("VT", "MA", "CA", "CT", "RI")# Never changes
bans <- c(2014, 2014, 2016, 2014, 2016)


# write.csv(plac_for_histogram4 %>% bind_rows(), "plac_for_histogram4.csv", row.names=FALSE)
# write.csv(plac_for_histogram6 %>% bind_rows(), "plac_for_histogram6.csv", row.names=FALSE)

#rm(plac_for_histogram4, plac_for_histogram6)
```

### County MAE

```{r}
plac_for_histogram4 <- read.csv("plac_for_histogram4.csv")
plac_for_histogram6 <- read.csv("plac_for_histogram6.csv")
mae_placebo <- 
  rbind(
    plac_for_histogram4 %>% 
      mutate(treated_state="boulderM2"), 
    plac_for_histogram6 %>% 
      mutate(treated_state= "seattleM1")) %>% 
  filter(sample_size!=0) %>% 
  group_by (treated_state, sample_size) %>% 
  summarise(
    mae_low = quantile(mape, 0.025) %>% round(3), 
    mae_high = quantile(mape, 0.975)%>% round(3)) 
  
```

### P-values

```{r}
# plac_for_histogram4 <- read.csv("plac_for_histogram4.csv")
# plac_for_histogram6 <- read.csv("plac_for_histogram6.csv")

p_se <- 
  plac_for_histogram6 %>% as_tibble %>% 
  left_join(
    bt_with_power_data %>% 
      filter(state_id=="Seattle, WA") %>% 
      select(sample_size, actual_treatment_effect, ban_year) %>% 
      rename(chosen_sample_size=sample_size), 
    by = "ban_year"
  ) %>% 
  filter(
    sample_size==chosen_sample_size, 
    donor_number=="donor_1"
  ) %>% 
  group_by(county_id, actual_treatment_effect) %>% 
  filter(mape==min(mape)) %>% 
  ungroup %>% 
  mutate(att = abs(att)) %>% 
  summarise(p=mean(att >= abs(actual_treatment_effect))) %>% pluck("p")


p_bo <- 
  plac_for_histogram4 %>% bind_rows() %>% as_tibble %>% 
  left_join(
    bt_with_power_data %>% 
      filter(state_id=="Boulder, CO") %>% 
      select(sample_size, actual_treatment_effect, ban_year) %>% 
      rename(chosen_sample_size=sample_size), 
    by = "ban_year"
  ) %>% 
  filter(
    sample_size==chosen_sample_size, 
    donor_number=="donor_1"
  ) %>% 
  group_by(county_id, actual_treatment_effect) %>% 
  filter(mape==min(mape)) %>% 
  ungroup %>% 
  mutate(att = abs(att)) %>% 
  summarise(p=mean(att >= abs(actual_treatment_effect))) %>% pluck("p")
  
  
figure_path <- "C:/Users/fa24575/Dropbox/Apps/Overleaf/Organic Waste Bans/Figures"

fileConn<-file(paste0(figure_path, "/p_se.txt"))
writeLines(paste0(format(scales::number(p_se, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)

fileConn<-file(paste0(figure_path, "/p_bo.txt"))
writeLines(paste0(format(scales::number(p_bo, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)


#rm(p_se, p_bo, plac_for_histogram6, plac_for_histogram4)
```

### Specs
The following chunk takes as input plac_for_histogram4 and plac_for_histogram6 (also saved as csvs) and produces the power specification for the city level bans. 
```{r}

plac_for_histogram4 <- read.csv("plac_for_histogram4.csv")
plac_for_histogram6 <- read.csv("plac_for_histogram6.csv")

power_county4 <- power_county(plac_for_histogram4 %>% bind_rows(), "CA")
power_county6 <- power_county(plac_for_histogram6 %>% bind_rows(), "M1")

# write.csv(rbind(
#   power_county4 %>%  bind_rows(),
#   power_county6 %>%  bind_rows()
# ), "power_county.csv", row.names=FALSE)

```

## State

### Fig. 2: Placebo distributions (right panel)

The following chunk produces: the SCs and the relevant placebo distributions for each ban and the aggregate case. 

The SC outcomes are saved in file: power_state_plac_data,csv (which is comprised by power_state_plac1, power_state_plac2, power_state_plac3, power_state_plac4, power_state_plac5, power_state_plac6)


The placebo distributions are saved in file: power_state.csv (which is comprised by power_state1, power_state2, power_state3, power_state4, power_state5, power_state6). 

```{r}
dt_state_initial <- pre_processing_dt_state(power2) #state-level disposal
treated_counties_id <- unique(dt_state_initial$county_id[dt_state_initial$state_id%in% all_treated]) # treated states id 
donors_state <- unique(dt_state_initial$county_id[!(dt_state_initial$state_id%in% all_treated)]) # all donor states
all_treated <- c("VT", "MA", "CA", "CT", "RI", "All")# Never changes
bans <- c(2014, 2014, 2016, 2014, 2016, 2015) #we assume that the aggregate ban is implemented in 2015
samp=seq(3,10) # possible values of |S|

#####
# For function  power_state_plac, we use as input the intial dataset (i.e., the placebo SCs). 
# power_state_plac function creates the SCs (i.e., applies our identification method for each non-treated state)
# This function returns: for each sample_size, the 100 best SCs
#####

power_state_plac1 <- power_state_plac("MA", dt_state_initial, 1) # SC outcomes for MA's ban
power_state_plac2 <- power_state_plac("CA", dt_state_initial, 1) # SC outcomes for CA's ban
power_state_plac3 <- power_state_plac("CT", dt_state_initial, 1)# SC outcomes for CT's ban
power_state_plac4 <- power_state_plac("RI", dt_state_initial, 1)# SC outcomes for RI's ban
power_state_plac5 <- power_state_plac("VT", dt_state_initial, 1)# SC outcomes for VT's ban
power_state_plac6 <- power_state_plac("All", dt_state_initial, 1) #needed for the aggregate case

# write.csv(
#   rbind(
#     power_state_plac1 %>% bind_rows %>% mutate(treated_state="MA"),
#     power_state_plac2 %>% bind_rows %>% mutate(treated_state="CA"),
#     power_state_plac3 %>% bind_rows %>% mutate(treated_state="CT"),
#     power_state_plac4 %>% bind_rows %>% mutate(treated_state="RI"),
#     power_state_plac5 %>% bind_rows %>% mutate(treated_state="VT"),
#     power_state_plac6 %>% bind_rows %>% mutate(treated_state="All")
# 
#   ),
#   "power_state_plac.csv", row.names=FALSE
# )


power_state_plac_data <- read.csv("power_state_plac_no_r_sq_filter.csv")
# power_state_plac_data <- 
#   rbind( #bring all of the data together
#     power_state_plac1 %>% bind_rows %>% mutate(treated_state="MA"),
#     power_state_plac2 %>% bind_rows %>% mutate(treated_state="CA"),
#     power_state_plac3 %>% bind_rows %>% mutate(treated_state="CT"),
#     power_state_plac4 %>% bind_rows %>% mutate(treated_state="RI"),
#     power_state_plac5 %>% bind_rows %>% mutate(treated_state="VT"),
#     power_state_plac6 %>% bind_rows %>% mutate(treated_state="All")
#   )

#####
# For function  power_state_fun2, we use as input the output of power_state_plac (i.e., the placebo SCs). 
# power_state_fun2 function creates the confidence intervals of the placebo inference. # The output is, for each sample size, a confidence interval (att_min, att_max), the mean of the placebo interval (titled att_mean) 
#####

power_state1 <- power_state_fun2(power_state_plac_data %>% filter(treated_state=="MA"), "MA") 
power_state2 <- power_state_fun2(power_state_plac_data %>% filter(treated_state=="CA"), "CA")
power_state3 <- power_state_fun2(power_state_plac_data %>% filter(treated_state=="CT"), "CT")
power_state4 <- power_state_fun2(power_state_plac_data %>% filter(treated_state=="RI"), "RI")
power_state5 <- power_state_fun2(power_state_plac_data %>% filter(treated_state=="VT"), "VT")
# 
#pool_estimates <- lapply(seq(1:length(donors_state)), pool_function, data = power_state_plac2 %>% bind_rows(), donors = donors_state , r_threshold = 0, mape_threshold = Inf, n =5)

####
# The following calculates the power for the aggregate case. 
# First, for each non-treated state, we apply the pool_function
# This function takes n (in our case 5) donors and uses their mean to approximate
# an "aggregate ban". We require power_state_plac6 because we assume that the ban_year
# for the aggregate case is 2015 (where no actual ban exists)
####

power_state_plac6 <- power_state_plac_data %>% filter(treated_state=="All")
pool_estimates <- lapply(seq(1:length(donors_state)), pool_function, data = power_state_plac6 %>% bind_rows(), donors = donors_state , r_threshold = 0, mape_threshold = Inf, n =5, seed=3)


#write.csv(pool_estimates %>% bind_rows() %>% mutate(treated_state ="All"), "pool_estimates_All.csv", row.names=FALSE )


power_state6 <- 
  pool_estimates %>% 
  bind_rows %>%  
  group_by(sample_size, ban_year) %>% 
  summarise(
    att_min = quantile(att, 0.025),
    att_max = quantile(att, 0.975),
    att_median = median(att)
  ) %>% mutate(
    specification = "State Pooled", year = 2015, treated_state="All"
  )

# 
# write.csv(
# rbind(
#   power_state1%>%  bind_rows(),
#   power_state2%>%  bind_rows(),
#   power_state3%>%  bind_rows(),
#   power_state4%>%  bind_rows(),
#   power_state5%>%  bind_rows(),
#   power_state6%>%  bind_rows()
#   ),
#   "power_state.csv", row.names = FALSE)

```

#### Rob. Check for Placebo CI
```{r}

power_state1_alt <- power_state_fun2_alternative(power_state_plac_data %>% filter(treated_state=="MA"), "MA") # the optimal number of donors changes from 7 to 6
power_state2_alt <- power_state_fun2_alternative(power_state_plac_data %>% filter(treated_state=="CA"), "CA") # same result
power_state3_alt <- power_state_fun2_alternative(power_state_plac_data %>% filter(treated_state=="CT"), "CT")# the optimal number of donors changes from 6 to 8
power_state4_alt <- power_state_fun2_alternative(power_state_plac_data %>% filter(treated_state=="RI"), "RI")# same result
power_state5_alt <- power_state_fun2_alternative(power_state_plac_data %>% filter(treated_state=="VT"), "VT")# same result
```


### P values

```{r}
effects_att <- 
  bt_with_power_data %>% 
  select(state_id, sample_size, actual_treatment_effect) %>% 
  rename(
    chosen_sample_size=sample_size, 
    effects = actual_treatment_effect
  ) %>% 
  mutate(
    state_id = state_id %>% as.character,
    state_id= ifelse(state_id=="All States", "All", state_id), 
    effects=abs(effects) 
  )



pool_estimates_All <- read.csv("pool_estimates_All.csv")

p_values_fun <- function (plac, treated_state)
{
  plac %>% 
    bind_rows %>% 
    mutate(treated_state= treated_state) %>% 
    group_by(sample_size, county_id,treated_state) %>% 
    filter(mape==min(mape), donor_number=="donor_1") %>% 
    group_by(mape, county_id, sample_size, treated_state) %>% 
    summarise(att=unique(att)) %>% 
    ungroup %>% 
    left_join(
      effects_att, by = c("treated_state" = "state_id")
    ) %>% 
    filter(sample_size==chosen_sample_size) %>% 
    mutate(att = abs(att)) %>% 
    summarise(p=mean(att >= effects))
}

power_state_plac_dt <- read.csv("power_state_plac_no_r_sq_filter.csv")

p_ma <- p_values_fun (power_state_plac_dt %>% filter(treated_state=="MA"), "MA") %>% pluck("p")
p_ca <- p_values_fun (power_state_plac_dt %>% filter(treated_state=="CA"), "CA") %>% pluck("p")
p_ct <- p_values_fun (power_state_plac_dt %>% filter(treated_state=="CT"), "CT") %>% pluck("p")
p_ri <- p_values_fun (power_state_plac_dt %>% filter(treated_state=="RI"), "RI") %>% pluck("p")
p_vt <- p_values_fun (power_state_plac_dt %>% filter(treated_state=="VT"), "VT") %>% pluck("p")
p_all <- p_values_fun (pool_estimates_All %>% mutate(treated_state="All") %>% rename(county_id=i) %>% mutate(donor_number="donor_1"), "All") %>% pluck("p")


figure_path <- "C:/Users/fa24575/Dropbox/Apps/Overleaf/Organic Waste Bans/Figures"

fileConn<-file(paste0(figure_path, "/p_ma.txt"))
writeLines(paste0(format(scales::number(p_ma, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/p_ca.txt"))
writeLines(paste0(format(scales::number(p_ca, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/p_ct.txt"))
writeLines(paste0(format(scales::number(p_ct, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/p_ri.txt"))
writeLines(paste0(format(scales::number(p_ri, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/p_vt.txt"))
writeLines(paste0(format(scales::number(p_vt, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/p_all.txt"))
writeLines(paste0(format(scales::number(p_all, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
```

###  Table S6: Mean of distributions
```{r}

power_state_mean_placebo <- 
  read.csv("power_state.csv") %>% as_tibble() %>%  
  filter(specification == "State") %>% 
  right_join(
    bt_with_power_data %>% 
      select(state_id, sample_size, actual_treatment_effect) %>% 
      rename(
        chosen_sample_size=sample_size 
      ), 
    by = c("treated_state"= "state_id", "sample_size"="chosen_sample_size")
  ) %>% 
  filter(!is.na(ban_year))
  
mean_ma <- power_state_mean_placebo %>% filter(treated_state=="MA") %>% pluck("att_median")*100
mean_ca <- power_state_mean_placebo %>% filter(treated_state=="CA") %>% pluck("att_median")*100
mean_ct <- power_state_mean_placebo %>% filter(treated_state=="CT") %>% pluck("att_median")*100
mean_ri <- power_state_mean_placebo %>% filter(treated_state=="RI") %>% pluck("att_median")*100
mean_vt <- power_state_mean_placebo %>% filter(treated_state=="VT") %>% pluck("att_median")*100


#figure_path <- "C:/Users/fa24575/Dropbox/Apps/Overleaf/Organic Waste Bans/Figures"

fileConn<-file(paste0(figure_path, "/mean_ma.txt"))
writeLines(paste0(format(scales::number(mean_ma, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/mean_ca.txt"))
writeLines(paste0(format(scales::number(mean_ca, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/mean_ct.txt"))
writeLines(paste0(format(scales::number(mean_ct, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/mean_ri.txt"))
writeLines(paste0(format(scales::number(mean_ri, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/mean_vt.txt"))
writeLines(paste0(format(scales::number(mean_vt, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)

```


### Table S6: MAPE distributions

```{r}

mape_placebo <- 
  power_state_plac_data %>% as_tibble() %>% 
  filter(sample_size!=0) %>% 
  mutate(county_id = as.character(county_id)) %>% 
  group_by(sample_size, ban_year, county_id, treated_state ) %>% 
  filter(mape==min(mape)) %>% 
  right_join(
    bt_with_power_data %>% 
      select(state_id, sample_size, actual_treatment_effect) %>% 
      rename(
        chosen_sample_size=sample_size 
      ), 
    by = c("treated_state"= "state_id", "sample_size"="chosen_sample_size")
  ) %>% 
  filter(!is.na(ban_year)) %>% 
  group_by(treated_state, county_id,sample_size) %>% 
  summarise(mape=mean(mape)) %>% 
    group_by(treated_state,sample_size) %>% 
  summarise(
    mape_high = 100*quantile(mape, 0.975), 
    mape_low = 100*quantile(mape, 0.025)
  )

mape_ma_upper <- mape_placebo %>% filter(treated_state=="MA") %>% pluck("mape_high")
mape_ma_lower <- mape_placebo %>% filter(treated_state=="MA") %>% pluck("mape_low")
mape_ca_upper <- mape_placebo %>% filter(treated_state=="CA") %>% pluck("mape_high")
mape_ca_lower <- mape_placebo %>% filter(treated_state=="CA") %>% pluck("mape_low")
mape_ct_upper <- mape_placebo %>% filter(treated_state=="CT") %>% pluck("mape_high")
mape_ct_lower <- mape_placebo %>% filter(treated_state=="CT") %>% pluck("mape_low")
mape_ri_upper <- mape_placebo %>% filter(treated_state=="RI") %>% pluck("mape_high")
mape_ri_lower <- mape_placebo %>% filter(treated_state=="RI") %>% pluck("mape_low")
mape_vt_upper <- mape_placebo %>% filter(treated_state=="VT") %>% pluck("mape_high")
mape_vt_lower <- mape_placebo %>% filter(treated_state=="VT") %>% pluck("mape_low")


#figure_path <- "C:/Users/fa24575/Dropbox/Apps/Overleaf/Organic Waste Bans/Figures"

fileConn<-file(paste0(figure_path, "/mape_ma_upper.txt"))
writeLines(paste0(format(scales::number(mape_ma_upper, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/mape_ma_lower.txt"))
writeLines(paste0(format(scales::number(mape_ma_lower, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)

fileConn<-file(paste0(figure_path, "/mape_ca_upper.txt"))
writeLines(paste0(format(scales::number(mape_ca_upper, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/mape_ca_lower.txt"))
writeLines(paste0(format(scales::number(mape_ca_lower, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)

fileConn<-file(paste0(figure_path, "/mape_ct_upper.txt"))
writeLines(paste0(format(scales::number(mape_ct_upper, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/mape_ct_lower.txt"))
writeLines(paste0(format(scales::number(mape_ct_lower, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)

fileConn<-file(paste0(figure_path, "/mape_ri_upper.txt"))
writeLines(paste0(format(scales::number(mape_ri_upper, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/mape_ri_lower.txt"))
writeLines(paste0(format(scales::number(mape_ri_lower, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)

fileConn<-file(paste0(figure_path, "/mape_vt_upper.txt"))
writeLines(paste0(format(scales::number(mape_vt_upper, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)
fileConn<-file(paste0(figure_path, "/mape_vt_lower.txt"))
writeLines(paste0(format(scales::number(mape_vt_lower, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)

rm(mape_ma_upper, mape_ma_lower, mape_ca_upper, mape_ca_lower, mape_ct_upper, mape_ct_lower, mape_ri_upper, mape_ri_lower, mape_vt_upper, mape_vt_lower)
```

## Passage 

### State

```{r}
samp <- c(3:10)
dt_state_initial <- pre_processing_dt_state(power2)
treated_counties_id <- unique(dt_state_initial$county_id[dt_state_initial$state_id%in% all_treated])
donors_state <- unique(dt_state_initial$county_id[!(dt_state_initial$state_id%in% all_treated)])
all_treated <- c("VT", "MA", "CA", "CT", "RI")# Never changes
bans <- c(2012, 2013, 2014, 2011, 2014)

power_state_pass1 <- power_state_plac("MA", dt_state_initial, 1)
power_state_pass2 <- power_state_plac("CA", dt_state_initial, 1)
power_state_pass3 <- power_state_plac("CT", dt_state_initial, 2)
power_state_pass4 <- power_state_plac("RI", dt_state_initial, 1)
power_state_pass5 <- power_state_plac("VT", dt_state_initial, 1)


power_state_pass_data <- 
  rbind(
    power_state_pass1 %>% bind_rows %>% mutate(treated_state="MA"),
    power_state_pass2 %>% bind_rows %>% mutate(treated_state="CA"),
    power_state_pass3 %>% bind_rows %>% mutate(treated_state="CT"),
    power_state_pass4 %>% bind_rows %>% mutate(treated_state="RI"),
    power_state_pass5 %>% bind_rows %>% mutate(treated_state="VT")
  )

write.csv(power_state_pass_data,"power_state_pass_data.csv", row.names=FALSE)
power_state_pass_data <- read.csv("power_state_pass_data.csv")



power_state_p1 <- power_state_fun2(power_state_pass_data %>% filter(treated_state=="MA"), "MA")
power_state_p2 <- power_state_fun2(power_state_pass_data %>% filter(treated_state=="CA"), "CA")
power_state_p3 <- power_state_fun2(power_state_pass_data %>% filter(treated_state=="CT"), "CT")
power_state_p4 <- power_state_fun2(power_state_pass_data %>% filter(treated_state=="RI"), "RI")
power_state_p5 <- power_state_fun2(power_state_pass_data %>% filter(treated_state=="VT"), "VT")



write.csv(
rbind(
  power_state_p1%>%  bind_rows(),
  power_state_p2%>%  bind_rows(),
  power_state_p3%>%  bind_rows(),
  power_state_p4%>%  bind_rows(),
  power_state_p5%>%  bind_rows()
),
  "power_state_p.csv", row.names = FALSE)

```



# Municipal

## Importing Data

```{r}
year_start = 2006
year_end = 2018
population_seattle <- read.csv(paste0(municipal_path,"/Seattle, WA/import_R/population_seattle.csv"))
composting <- read.csv(paste0(municipal_path,"/Seattle, WA/import_R/seattle_composting.csv"))
disposal <- read.csv(paste0(municipal_path,"/Seattle, WA/import_R/seattle_disposal.csv"))

seattle <- 
  disposal %>%
  rename(
    total = Landfill,
    year = Year, 
    month = Month
  ) %>% 
  pivot_longer(
    cols = c("Self_Haul", "Residential", "Commercial"), 
    names_to = "generator", 
    values_to = "tons"
  ) %>%  
  mutate(
    type = "disposal", 
    generator = str_to_lower(generator)
  ) %>% 
  select(
    year, month, generator, tons, type
  ) %>% 
  rbind(
    composting %>%
      pivot_longer(
        cols = c("self_haul", "residential", "commercial"), 
        names_to = "generator", 
        values_to = "tons"
      ) %>%  
      mutate(
        type = "composting"
      )
  ) %>%  
  group_by(year, type) %>%  
  summarise(
    tons = sum(tons, na.rm = TRUE)
  ) %>% 
  left_join(
    population_seattle %>%  
      rename (pop=population) %>% 
      select (year, pop), 
    by = c("year")
  ) %>%  
  mutate (
    tons_pc = tons/pop,
    state_id = "M1", 
    county_name = "seattle", 
    county_id = paste(county_name, state_id, sep = ""), 
  ) 

waste <- read.csv(paste0(municipal_path,"/Boulder, CO/import_R/boulder_waste.csv"))
boulder_population <- read.csv(paste0(municipal_path,"/Boulder, CO/import_R/boulder_population.csv"))

colnames(waste) <- c("year", "sector", "disposal", "recycling", "organics","reuse", "total", "diversion", "notes")

boulder <- 
  waste %>% 
  filter(
    year >= 2006, 
  ) %>%  
  pivot_longer(
    cols = c("disposal", "recycling", "organics", "reuse", "total"), 
    names_to = "type", 
    values_to = "tons"
  ) %>%  
  select(
    year, type, tons
  ) %>% 
  group_by(year, type) %>% 
  summarise(
    tons = sum(tons, na.rm = TRUE)
  ) %>% 
  left_join(
    boulder_population %>%  
      rename(pop=population),
    by = c("year")) %>%  
  mutate (
    tons_pc = tons/pop, 
    state_id = "M2", 
    county_name = "boulder", 
    county_id = paste(county_name, state_id, sep = ""), 
    type = ifelse(type == "organics", "composting", type)
  )
```

## Transforming data
```{r}
dt_initial <- pre_processing_dt(power2)

dt_municipal <- 
  dt_initial %>%
  select(year, state_id, county_id, tons_pc, tons) %>%
  rbind(
    seattle %>%  
      filter(
        type == "disposal", 
        year >= year_start, 
        year <= 2018
      ) %>%  
      select(year, state_id, county_id, tons_pc, tons), 
    boulder %>%  
      filter(
        type == "disposal", 
        year >= year_start, 
        year <= 2018
      ) %>%  
      select(year, state_id, county_id, tons_pc, tons)
  ) %>% 
  filter(
    !state_id %in% c("WA", "CO")
  ) %>% 
  as.data.frame

dt_municipal_initial <- dt_municipal
```

### San Francisco

```{r}
year_start <- 1996
year_cutoff <- 2014
year_end <- 2011


dt <- 
  power2 %>% 
  filter(
    year >= year_start, 
    year <= year_cutoff, 
    type %in% c("disposal", "msw_disposed"),
    state_id=="CA"
  ) %>% 
  group_by(county_name) %>% 
  mutate(
    tons_high = quantile(tons, 0.975), 
    tons_low = quantile(tons, 0.025), 
    tons = ifelse(tons> tons_high, tons_high, tons), 
    tons = ifelse(tons< tons_low, tons_low, tons)
  ) %>% 
  select(-tons_high) %>% select(-tons_low) %>% 
  group_by (year, state_id, county_name) %>% 
  summarise(tons = sum(tons)) %>% 
  left_join (
    population %>% group_by(state_id, year) %>% summarise(state_pop = sum(pop)), 
    by = c("state_id", "year")
  ) %>%
  left_join (
    population,
    by = c("state_id", "county_name", "year")
  ) %>% 
  mutate(
    tons_pc = ifelse(is.na(county_name),tons/state_pop, tons/pop), 
    county_id = ifelse(is.na(county_name), state_id, paste0(county_name, state_id)),
    county_id = ifelse(county_id=="san franciscoCA", "san franciscoM3", county_id),
    state_id = ifelse(county_id == "san franciscoM3", "M3", "other")
  )

# Power 
dt <- dt %>%  as.data.frame()
treated_counties_id <- unique(dt$county_id[dt$state_id%in% all_treated])
dt <- dt[!(dt$state_id %in% all_treated),] %>% as.data.frame
donors <- unique(dt$county_id[!(dt$state_id%in% all_treated)])

ban_year <- bans[which(all_treated == treated_state)]

plac <- lapply(seq(1:length(donors)),in_sample_R2_same_state,dt, donors=donors, iterations_scale=1000, option="V2", ban_year=ban_year, offset=3, samp =samp, seed=1)

write.csv(plac %>% bind_rows, "plac_sf.csv", row.names = FALSE) 

sf_power <- 
  plac %>% 
  bind_rows %>% 
  group_by(sample_size, county_id,ban_year) %>% 
  summarise(att=mean(att)) %>% 
  group_by(sample_size, ban_year) %>% 
  summarise(
    att_min = quantile(att, 0.025), 
    att_max = quantile(att, 0.975), 
    att_median = median(att)) %>% 
  mutate(year = 2009, specification = "County", treated_state = "M3")

write.csv(sf_power,"sf_power.csv", row.names = FALSE)


```

#### P values

```{r}
plac_sf <- read.csv("plac_sf.csv")

p_sf <- 
  plac_sf %>% as_tibble %>% 
  left_join(
    bt_with_power_data %>% 
      filter(state_id=="San Francisco, CA") %>% 
      select(sample_size, actual_treatment_effect, ban_year) %>% 
      rename(chosen_sample_size=sample_size), 
    by = "ban_year"
  ) %>% 
  filter(
    sample_size==chosen_sample_size, 
    donor_number=="donor_1"
  ) %>% 
  group_by(county_id, actual_treatment_effect) %>% 
  filter(mape==min(mape)) %>% 
  ungroup %>% 
  mutate(att = abs(att)) %>% 
  summarise(p=mean(att >= abs(actual_treatment_effect))) %>% pluck("p")
  
  
figure_path <- "C:/Users/fa24575/Dropbox/Apps/Overleaf/Organic Waste Bans/Figures"

fileConn<-file(paste0(figure_path, "/p_sf.txt"))
writeLines(paste0(format(scales::number(p_sf, accuracy = 0.01),big.mark=",",scientific=FALSE),'%'), fileConn)
close(fileConn)

```



#### SF MAE

```{r}
plac_sf <- read.csv("plac_sf.csv")
mae_placebo <- 
  rbind(
    mae_placebo, 
    plac_sf %>% mutate(treated_state= "san franciscoM3") %>% filter(sample_size!=0) %>% 
      group_by (treated_state, sample_size) %>% 
      summarise(mae_low = quantile(mape, 0.05) %>% round(3), mae_high = quantile(mape, 0.95)%>% round(3)) )

write.csv(mae_placebo, "mae_placebo.csv", row.names=FALSE)

```

